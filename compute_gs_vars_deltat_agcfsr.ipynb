{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import datetime\n",
    "import numba\n",
    "from numba import jit,prange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2002, 2003, 2004, 2005, 2006, 2007, 2008]\n"
     ]
    }
   ],
   "source": [
    "infolder = \"D:/data/AgCFSR/regrid/\"\n",
    "\n",
    "calname = \"Sacks_ZARC_fill_fill_120d\"\n",
    "\n",
    "outfolder = \"agcfsr_computed/\"+calname+\"/\"\n",
    "\n",
    "masterpref = \"AgCFSR_\"\n",
    "tempsuf = \"_tavg.nc4\"\n",
    "tmaxsuf = \"_tmax.nc4\"\n",
    "tminsuf = \"_tmin.nc4\"\n",
    "\n",
    "calfolder = \"agcfsr_calendars/\"+calname+\"/\"\n",
    "calsuf = \".crop.calendar.fill.nc\"\n",
    "planvar = \"plant.start\"\n",
    "harvvar = \"harvest.end\"\n",
    "\n",
    "mskfname = infolder+\"seamask.nc\"\n",
    "\n",
    "crops = [\"Soybeans\",\"Maize\",\"Cotton\"]\n",
    "# crops = [\"Maize\",\"Soybeans\",\"Rice\",\"Wheat\"]\n",
    "# crops = [\"Soybeans\"]\n",
    "\n",
    "# The basis of calculation will be harvest years\n",
    "# hyears = [2002]\n",
    "# hyears = [2003]\n",
    "# hyears = [2009]\n",
    "# hyears = [2009,2010,2011,2012,2013,2014]\n",
    "# hyears = [2010,2011,2012,2013,2014]\n",
    "hyears = list(range(2002,2008+1))\n",
    "# hyears = list(range(2002,2003+1))\n",
    "print(hyears)\n",
    "\n",
    "deltats = [1,2,3,4,5]\n",
    "\n",
    "# Parameters for evaluating the temperature distribution\n",
    "# Tlo = -5.0\n",
    "# Thi = 50.0\n",
    "# Tint = 1.0\n",
    "Tlo = 10.0\n",
    "Thi = 39.0\n",
    "Tint = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens and concatenates a harvest year with the equivalent planting year\n",
    "# def concat_clim(infolder,climpref,hyear):\n",
    "def concat_clim(infolder,masterpref,climsuf,hyear):\n",
    "    pyear = hyear - 1\n",
    "\n",
    "#     climharr = xr.open_dataarray(infolder+climpref+str(hyear)+\".nc\")\n",
    "#     climparr = xr.open_dataarray(infolder+climpref+str(pyear)+\".nc\")\n",
    "#     climharr = xr.open_dataarray(infolder+masterpref+str(hyear)+climsuf+\".nc\")\n",
    "#     climparr = xr.open_dataarray(infolder+masterpref+str(pyear)+climsuf+\".nc\")\n",
    "    climharr = xr.open_dataarray(infolder+masterpref+str(hyear)+climsuf, decode_times = False)\n",
    "    climparr = xr.open_dataarray(infolder+masterpref+str(pyear)+climsuf, decode_times = False)\n",
    "\n",
    "    climarr = xr.concat([climparr,climharr], dim = \"time\")\n",
    "    return climarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates t distribution for a single day\n",
    "@jit(nopython=True)\n",
    "def calc_dist_day(Tmin,Tmax,Tl1s,Tint):\n",
    "    res = 0.005 #Resolution (dt, in days) on which to evaluate the T sine curve\n",
    "\n",
    "#     Tl1s = np.arange(Tlo,Thi,Tint)\n",
    "    nT = Tl1s.shape[0]\n",
    "    exps = np.zeros_like(Tl1s)\n",
    "\n",
    "    t = np.arange(0,1,res)\n",
    "    nt = t.shape[0]\n",
    "\n",
    "    Tamp = (Tmax-Tmin)/2.0\n",
    "    Tmed = (Tmax+Tmin)/2.0\n",
    "\n",
    "    T = Tmed + Tamp*np.sin(t*(2.0*np.pi/1))\n",
    "\n",
    "    for tcount in range(nT):\n",
    "        Tl1 = Tl1s[tcount]\n",
    "        Tl2 = Tl1 + Tint\n",
    "        exps[tcount] = np.sum(np.invert(np.isnan(\n",
    "            np.where((T>=Tl1) & (T<=Tl2) ,T,np.nan)\n",
    "        )))/nt\n",
    "    return exps\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calc_dist_point(tmaxvec,tminvec,Tlos,Tint):\n",
    "    allexps = np.zeros_like(Tlos)\n",
    "    for day in range(tminvec.shape[0]):\n",
    "        allexps = allexps + calc_dist_day(tminvec[day],tmaxvec[day],Tlos,Tint)\n",
    "    return allexps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates GDD for a single day\n",
    "@jit(nopython=True)\n",
    "def calc_gdd_day(Tmin,Tmax,Tl1s):\n",
    "    res = 0.005 #Resolution (dt, in days) on which to evaluate the T sine curve\n",
    "\n",
    "    #     Tl1s = np.arange(Tlo,Thi,Tint)\n",
    "    nT = Tl1s.shape[0]\n",
    "    gdds = np.zeros_like(Tl1s)\n",
    "\n",
    "    t = np.arange(0,1,res)\n",
    "    nt = t.shape[0]\n",
    "\n",
    "    Tamp = (Tmax-Tmin)/2.0\n",
    "    Tmed = (Tmax+Tmin)/2.0\n",
    "\n",
    "    T = Tmed + Tamp*np.sin(t*(2.0*np.pi/1))\n",
    "\n",
    "    for tcount in range(nT):\n",
    "        Tl1 = Tl1s[tcount]\n",
    "        gdds[tcount] = np.sum(np.invert(np.isnan(\n",
    "            np.where((T>=Tl1),T,np.nan)\n",
    "        ))*(T-Tl1))/nt\n",
    "\n",
    "    return gdds\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calc_gdd_point(tmaxvec,tminvec,Tlos):\n",
    "    allgdds = np.zeros_like(Tlos)\n",
    "    for day in range(tminvec.shape[0]):\n",
    "        allgdds = allgdds + calc_gdd_day(tminvec[day],tmaxvec[day],Tlos)\n",
    "    return allgdds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates everything for the growing season given numpy arrays. \n",
    "# Loops throught the points and calculates both distribution and regular gs means\n",
    "# Compiles with Numba parallel\n",
    "@jit(nopython=True, parallel = True)\n",
    "# @jit(nopython=True)\n",
    "def calc_all(planmat,harvmat,tempmat,tmaxmat,tminmat,\n",
    "             tempmeanmat,tmaxmeanmat,tminmeanmat,\n",
    "             trngmeanmat,ndaymat,\n",
    "             tempdistmat,tempgddsmat):\n",
    "    for lati in prange(tempmat.shape[1]):\n",
    "        for lonj in range(tempmat.shape[2]):\n",
    "            if (np.isnan(planmat[lati,lonj])) or (np.isnan(tempmat[0,lati,lonj])):\n",
    "                continue\n",
    "            plan = int(planmat[lati,lonj])\n",
    "            harv = int(harvmat[lati,lonj])\n",
    "\n",
    "            tempvec = tempmat[plan:harv,lati,lonj]\n",
    "            tmaxvec = tmaxmat[plan:harv,lati,lonj]\n",
    "            tminvec = tminmat[plan:harv,lati,lonj]\n",
    "\n",
    "            tempmeanmat[lati,lonj] = np.nanmean(tempvec)\n",
    "            tmaxmeanmat[lati,lonj] = np.nanmean(tmaxvec)\n",
    "            tminmeanmat[lati,lonj] = np.nanmean(tminvec)\n",
    "            trngmeanmat[lati,lonj] = np.nanmean(tmaxvec - tminvec)\n",
    "            ndaymat[lati,lonj] = np.int64(harv-plan)\n",
    "            tempdistmat[:,lati,lonj] = calc_dist_point(tmaxvec,tminvec,Tlos,Tint)\n",
    "            tempgddsmat[:,lati,lonj] = calc_gdd_point(tmaxvec,tminvec,Tlos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates everything for the growing season given numpy arrays. EXCEPT TDIST!\n",
    "# Loops throught the points and calculates both distribution and regular gs means\n",
    "# Compiles with Numba parallel\n",
    "@jit(nopython=True, parallel = True)\n",
    "# @jit(nopython=True)\n",
    "def calc_all_but_tdist(planmat,harvmat,tempmat,tmaxmat,tminmat,\n",
    "             tempmeanmat,tmaxmeanmat,tminmeanmat,\n",
    "             trngmeanmat,ndaymat,\n",
    "             tempgddsmat):\n",
    "    for lati in prange(tempmat.shape[1]):\n",
    "        for lonj in range(tempmat.shape[2]):\n",
    "            if (np.isnan(planmat[lati,lonj])) or (np.isnan(tempmat[0,lati,lonj])):\n",
    "                continue\n",
    "            plan = int(planmat[lati,lonj])\n",
    "            harv = int(harvmat[lati,lonj])\n",
    "\n",
    "            tempvec = tempmat[plan:harv,lati,lonj]\n",
    "            tmaxvec = tmaxmat[plan:harv,lati,lonj]\n",
    "            tminvec = tminmat[plan:harv,lati,lonj]\n",
    "\n",
    "            tempmeanmat[lati,lonj] = np.nanmean(tempvec)\n",
    "            tmaxmeanmat[lati,lonj] = np.nanmean(tmaxvec)\n",
    "            tminmeanmat[lati,lonj] = np.nanmean(tminvec)\n",
    "            trngmeanmat[lati,lonj] = np.nanmean(tmaxvec - tminvec)\n",
    "            ndaymat[lati,lonj] = np.int64(harv-plan)\n",
    "#             tempdistmat[:,lati,lonj] = calc_dist_point(tmaxvec,tminvec,Tlos,Tint)\n",
    "            tempgddsmat[:,lati,lonj] = calc_gdd_point(tmaxvec,tminvec,Tlos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soybeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [08:02<48:17, 482.95s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [15:18<39:04, 468.80s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:43<30:45, 461.45s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [30:13<22:54, 458.21s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:44<15:12, 456.01s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:06<07:31, 451.81s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:30<00:00, 450.03s/it]\n",
      " 20%|████████████████                                                                | 1/5 [52:30<3:30:00, 3150.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:39<45:54, 459.00s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [15:16<38:12, 458.52s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:40<30:16, 454.13s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [29:54<22:24, 448.22s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:30<15:00, 450.42s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:17<07:35, 455.60s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:55<00:00, 453.58s/it]\n",
      " 40%|███████████████████████████████▏                                              | 2/5 [1:45:25<2:37:52, 3157.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:27<44:45, 447.64s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:56<37:20, 448.10s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:28<29:56, 449.09s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [30:01<22:30, 450.28s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:25<14:57, 448.51s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [44:55<07:28, 448.92s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:26<00:00, 449.47s/it]\n",
      " 60%|██████████████████████████████████████████████▊                               | 3/5 [2:37:51<1:45:08, 3154.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:40<46:05, 460.95s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [15:19<38:21, 460.32s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:48<30:26, 456.71s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [30:20<22:46, 455.56s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:55<15:10, 455.30s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:26<07:33, 453.93s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [53:09<00:00, 455.58s/it]\n",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [3:31:00<52:44, 3164.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:19<43:59, 439.94s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:46<36:49, 441.96s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:14<29:34, 443.64s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [29:51<22:23, 447.83s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:36<15:05, 452.80s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:08<07:32, 452.67s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:33<00:00, 450.47s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [4:23:33<00:00, 3162.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:20<44:02, 440.40s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:41<36:42, 440.56s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:19<29:43, 445.86s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [29:55<22:26, 448.81s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:24<14:58, 449.06s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:00<07:31, 451.00s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:24<00:00, 449.26s/it]\n",
      " 20%|████████████████                                                                | 1/5 [52:24<3:29:39, 3144.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:28<44:49, 448.26s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:53<37:16, 447.40s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:33<30:04, 451.04s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [30:18<22:46, 455.35s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:43<15:04, 452.29s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:06<07:29, 449.48s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:52<00:00, 453.17s/it]\n",
      " 40%|███████████████████████████████▏                                              | 2/5 [1:45:17<2:37:39, 3153.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:33<45:18, 453.04s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:49<37:20, 448.04s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:11<29:45, 446.39s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [29:29<22:11, 443.85s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [36:58<14:50, 445.26s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [44:38<07:29, 449.60s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [51:57<00:00, 445.42s/it]\n",
      " 60%|██████████████████████████████████████████████▊                               | 3/5 [2:37:14<1:44:45, 3142.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:31<45:09, 451.52s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [14:56<37:27, 449.53s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:29<30:02, 450.66s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [30:11<22:42, 454.03s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:37<15:03, 451.59s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:09<07:31, 451.72s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:36<00:00, 450.87s/it]\n",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [3:29:51<52:26, 3146.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:39<45:56, 459.42s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [15:07<37:59, 455.91s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:30<30:09, 452.25s/it]\n",
      " 57%|███████████████████████████████████████████████▍                                   | 4/7 [29:56<22:30, 450.19s/it]\n",
      " 71%|███████████████████████████████████████████████████████████▎                       | 5/7 [37:32<15:04, 452.11s/it]\n",
      " 86%|███████████████████████████████████████████████████████████████████████▏           | 6/7 [45:09<07:33, 453.41s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [52:43<00:00, 451.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [4:22:34<00:00, 3150.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cotton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      " 14%|███████████▊                                                                       | 1/7 [07:41<46:07, 461.33s/it]\n",
      " 29%|███████████████████████▋                                                           | 2/7 [15:11<38:09, 457.83s/it]\n",
      " 43%|███████████████████████████████████▌                                               | 3/7 [22:28<30:06, 451.68s/it]"
     ]
    }
   ],
   "source": [
    "# Create output folder\n",
    "if not os.path.exists(outfolder): os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "# Read the mask\n",
    "mskarr = xr.open_dataarray(mskfname)\n",
    "    \n",
    "#FIXME: Loop crops here\n",
    "for crop in crops:\n",
    "    print(crop)\n",
    "\n",
    "    # Open calendar and convert it to two-year based indexes. FIXME: Ignoring leap years here\n",
    "    caldata = xr.open_dataset(calfolder+crop+calsuf)\n",
    "    planarr = caldata[planvar]\n",
    "    harvarr = caldata[harvvar]\n",
    "    harvarr = xr.where(harvarr < planarr,harvarr + 365,harvarr) - 1 \n",
    "    \n",
    "    for deltat in tqdm.tqdm(deltats):\n",
    "        print(deltat)\n",
    "\n",
    "        #FIXME: Loop here\n",
    "        # hyear = hyears[0]\n",
    "        for hyear in tqdm.tqdm(hyears):\n",
    "            # Open the climate arrays, concatenating them\n",
    "            temparr = concat_clim(infolder,masterpref,tempsuf,hyear) + deltat\n",
    "            tmaxarr = concat_clim(infolder,masterpref,tmaxsuf,hyear) + deltat\n",
    "            tminarr = concat_clim(infolder,masterpref,tminsuf,hyear) + deltat\n",
    "\n",
    "            temparr = temparr.where(mskarr == 1)\n",
    "            tmaxarr = tmaxarr.where(mskarr == 1)\n",
    "            tminarr = tminarr.where(mskarr == 1)\n",
    "\n",
    "            # Generate a vector of lower T bounds to use as metadata and speed up computation\n",
    "            Tlos = np.arange(Tlo,Thi,Tint)\n",
    "\n",
    "            # Preallocate the arrays that will be filled\n",
    "            lldims = (\"latitude\",\"longitude\")\n",
    "    #         lldims = (\"lat\",\"lon\")\n",
    "            coords = [(i,temparr.coords[i].data,temparr.coords[i].attrs) for i in lldims] # Tuples with lat and lon dimension specs\n",
    "\n",
    "            # 2D arrays\n",
    "            tempmean = xr.DataArray(coords = coords, name = \"tempmean\")\n",
    "            tmaxmean = xr.DataArray(coords = coords, name = \"tmaxmean\")\n",
    "            tminmean = xr.DataArray(coords = coords, name = \"tminmean\")\n",
    "\n",
    "            trngmean = xr.DataArray(coords = coords, name = \"trngmean\")\n",
    "\n",
    "            ndayarr = xr.DataArray(coords = coords, name = \"ndays\")\n",
    "\n",
    "            # 2D + tmp arrays\n",
    "            tmp = (\"tmp\",Tlos,{\"long_name\":\"Temperature interval lower bound\",\"units\":\"degC\"})\n",
    "            coords3d = [tmp] + coords\n",
    "            tempdist = xr.DataArray(np.nan, coords = coords3d, name = \"tempdist\")\n",
    "            tempgdds = xr.DataArray(np.nan, coords = coords3d, name = \"tempgdds\")\n",
    "\n",
    "            # This basically creates pointers to the numpy arrays inside the xr.Dataarrays\n",
    "            # We need those for numba to work. An alternative would be passing the .data in the function call\n",
    "            planmat = planarr.data\n",
    "            harvmat = harvarr.data\n",
    "\n",
    "            tempmat = temparr.data\n",
    "            tmaxmat = tmaxarr.data\n",
    "            tminmat = tminarr.data\n",
    "\n",
    "            tempmeanmat = tempmean.data\n",
    "            tmaxmeanmat = tmaxmean.data\n",
    "            tminmeanmat = tminmean.data\n",
    "\n",
    "            trngmeanmat = trngmean.data\n",
    "\n",
    "            ndaymat = ndayarr.data\n",
    "\n",
    "            tempdistmat = tempdist.data\n",
    "            tempgddsmat = tempgdds.data\n",
    "\n",
    "\n",
    "            # Calculates everything.\n",
    "    #         calc_all(planmat,harvmat,tempmat,tmaxmat,tminmat,\n",
    "    #                  tempmeanmat,tmaxmeanmat,tminmeanmat,\n",
    "    #                  trngmeanmat,ndaymat,\n",
    "    #                  tempdistmat,tempgddsmat)\n",
    "                    # Calculates everything.\n",
    "            calc_all_but_tdist(planmat,harvmat,tempmat,tmaxmat,tminmat,\n",
    "                     tempmeanmat,tmaxmeanmat,tminmeanmat,\n",
    "                     trngmeanmat,ndaymat,\n",
    "                     tempgddsmat)\n",
    "\n",
    "\n",
    "            # Merge everything in a single Dataset\n",
    "    #         outdata = xr.merge([tempmean,tmaxmean,tminmean,trngmean,ndayarr,tempdist,tempgdds])\n",
    "            outdata = xr.merge([tempmean,tmaxmean,tminmean,trngmean,ndayarr,tempgdds])\n",
    "            outdata.attrs['Crop'] = crop\n",
    "            outdata.attrs['harvest_year'] = hyear\n",
    "            outdata.attrs['calendar_path'] = calfolder+crop+calsuf\n",
    "            outdata.attrs['climdata_path'] = infolder\n",
    "    #         outdata.attrs['climdata_ex_path'] = infolder+temppref+str(hyear)+\".nc\"\n",
    "\n",
    "            # Write output\n",
    "            outfname = outfolder + crop + \".computed.deltat.\" + str(deltat) + \".\" + str(hyear) + \".nc\"\n",
    "            outdata.to_netcdf(outfname,\n",
    "                      engine = \"netcdf4\",\n",
    "                      encoding = {\"tempgdds\":{'zlib': True, 'complevel': 1}} )\n",
    "    #         outdata.to_netcdf(outfname)\n",
    "    #         outdata.to_netcdf(outfname,\n",
    "    #                   engine = \"netcdf4\",\n",
    "    #                   encoding = {\"tempdist\":{'zlib': True, 'complevel': 1},\n",
    "    #                              \"tempgdds\":{'zlib': True, 'complevel': 1}} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create output folder\n",
    "# if not os.path.exists(outfolder): os.makedirs(outfolder, exist_ok=True)\n",
    "\n",
    "# # Read the mask\n",
    "# mskarr = xr.open_dataarray(mskfname)\n",
    "\n",
    "# #FIXME: Loop crops here\n",
    "# crop = crops[1]\n",
    "# # for crop in crops:\n",
    "# print(crop)\n",
    "\n",
    "# # Open calendar and convert it to two-year based indexes. FIXME: Ignoring leap years here\n",
    "# caldata = xr.open_dataset(calfolder+crop+calsuf)\n",
    "# planarr = caldata[planvar]\n",
    "# harvarr = caldata[harvvar]\n",
    "# harvarr = xr.where(harvarr < planarr,harvarr + 365,harvarr) - 1 \n",
    "\n",
    "# #FIXME: Loop here\n",
    "# hyear = hyears[0]\n",
    "# #     for hyear in tqdm.tqdm(hyears):\n",
    "# # Open the climate arrays, concatenating them\n",
    "# temparr = concat_clim(infolder,masterpref,tempsuf,hyear)\n",
    "# tmaxarr = concat_clim(infolder,masterpref,tmaxsuf,hyear)\n",
    "# tminarr = concat_clim(infolder,masterpref,tminsuf,hyear)\n",
    "\n",
    "# temparr = temparr.where(mskarr == 1)\n",
    "# tmaxarr = tmaxarr.where(mskarr == 1)\n",
    "# tminarr = tminarr.where(mskarr == 1)\n",
    "\n",
    "# # Generate a vector of lower T bounds to use as metadata and speed up computation\n",
    "# Tlos = np.arange(Tlo,Thi,Tint)\n",
    "\n",
    "# # Preallocate the arrays that will be filled\n",
    "# lldims = (\"latitude\",\"longitude\")\n",
    "# #         lldims = (\"lat\",\"lon\")\n",
    "# coords = [(i,temparr.coords[i].data,temparr.coords[i].attrs) for i in lldims] # Tuples with lat and lon dimension specs\n",
    "\n",
    "# # 2D arrays\n",
    "# tempmean = xr.DataArray(coords = coords, name = \"tempmean\")\n",
    "# tmaxmean = xr.DataArray(coords = coords, name = \"tmaxmean\")\n",
    "# tminmean = xr.DataArray(coords = coords, name = \"tminmean\")\n",
    "\n",
    "# trngmean = xr.DataArray(coords = coords, name = \"trngmean\")\n",
    "\n",
    "# ndayarr = xr.DataArray(coords = coords, name = \"ndays\")\n",
    "\n",
    "# # 2D + tmp arrays\n",
    "# tmp = (\"tmp\",Tlos,{\"long_name\":\"Temperature interval lower bound\",\"units\":\"degC\"})\n",
    "# coords3d = [tmp] + coords\n",
    "# tempdist = xr.DataArray(np.nan, coords = coords3d, name = \"tempdist\")\n",
    "# tempgdds = xr.DataArray(np.nan, coords = coords3d, name = \"tempgdds\")\n",
    "\n",
    "# # This basically creates pointers to the numpy arrays inside the xr.Dataarrays\n",
    "# # We need those for numba to work. An alternative would be passing the .data in the function call\n",
    "# planmat = planarr.data\n",
    "# harvmat = harvarr.data\n",
    "\n",
    "# tempmat = temparr.data\n",
    "# tmaxmat = tmaxarr.data\n",
    "# tminmat = tminarr.data\n",
    "\n",
    "# tempmeanmat = tempmean.data\n",
    "# tmaxmeanmat = tmaxmean.data\n",
    "# tminmeanmat = tminmean.data\n",
    "\n",
    "# trngmeanmat = trngmean.data\n",
    "\n",
    "# ndaymat = ndayarr.data\n",
    "\n",
    "# tempdistmat = tempdist.data\n",
    "# tempgddsmat = tempgdds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lati = 440\n",
    "# lonj = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan = int(planmat[lati,lonj])\n",
    "# harv = int(harvmat[lati,lonj])\n",
    "\n",
    "# tempvec = tempmat[plan:harv,lati,lonj]\n",
    "# tmaxvec = tmaxmat[plan:harv,lati,lonj]\n",
    "# tminvec = tminmat[plan:harv,lati,lonj]\n",
    "\n",
    "# tempmeanmat[lati,lonj] = np.nanmean(tempvec)\n",
    "# tmaxmeanmat[lati,lonj] = np.nanmean(tmaxvec)\n",
    "# tminmeanmat[lati,lonj] = np.nanmean(tminvec)\n",
    "# trngmeanmat[lati,lonj] = np.nanmean(tmaxvec - tminvec)\n",
    "# ndaymat[lati,lonj] = np.int64(harv-plan)\n",
    "# #             tempdistmat[:,lati,lonj] = calc_dist_point(tmaxvec,tminvec,Tlos,Tint)\n",
    "# # tempgddsmat[:,lati,lonj] = calc_gdd_point(tmaxvec,tminvec,Tlos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_gdd_point(tmaxvec,tminvec,Tlos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculates everything.\n",
    "# #         calc_all(planmat,harvmat,tempmat,tmaxmat,tminmat,\n",
    "# #                  tempmeanmat,tmaxmeanmat,tminmeanmat,\n",
    "# #                  trngmeanmat,ndaymat,\n",
    "# #                  tempdistmat,tempgddsmat)\n",
    "#         # Calculates everything.\n",
    "# calc_all_but_tdist(planmat,harvmat,tempmat,tmaxmat,tminmat,\n",
    "#          tempmeanmat,tmaxmeanmat,tminmeanmat,\n",
    "#          trngmeanmat,ndaymat,\n",
    "#          tempgddsmat)\n",
    "\n",
    "\n",
    "# # Merge everything in a single Dataset\n",
    "# #         outdata = xr.merge([tempmean,tmaxmean,tminmean,trngmean,ndayarr,tempdist,tempgdds])\n",
    "# outdata = xr.merge([tempmean,tmaxmean,tminmean,trngmean,ndayarr,tempgdds])\n",
    "# outdata.attrs['Crop'] = crop\n",
    "# outdata.attrs['harvest_year'] = hyear\n",
    "# outdata.attrs['calendar_path'] = calfolder+crop+calsuf\n",
    "# outdata.attrs['climdata_path'] = infolder\n",
    "# #         outdata.attrs['climdata_ex_path'] = infolder+temppref+str(hyear)+\".nc\"\n",
    "\n",
    "# # Write output\n",
    "# outfname = outfolder + crop + \".computed.\" + str(hyear) + \".nc\"\n",
    "# outdata.to_netcdf(outfname,\n",
    "#           engine = \"netcdf4\",\n",
    "#           encoding = {\"tempgdds\":{'zlib': True, 'complevel': 1}} )\n",
    "# #         outdata.to_netcdf(outfname)\n",
    "# #         outdata.to_netcdf(outfname,\n",
    "# #                   engine = \"netcdf4\",\n",
    "# #                   encoding = {\"tempdist\":{'zlib': True, 'complevel': 1},\n",
    "# #                              \"tempgdds\":{'zlib': True, 'complevel': 1}} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# climharr.sel(latitude = -16, longitude = -55, method = \"nearest\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# climsuf = tempsuf\n",
    "# pyear = hyear - 1\n",
    "\n",
    "# climharr = xr.open_dataarray(infolder+masterpref+str(hyear)+climsuf, decode_times = False)\n",
    "# climparr = xr.open_dataarray(infolder+masterpref+str(pyear)+climsuf, decode_times = False)\n",
    "\n",
    "# climarr = xr.concat([climparr,climharr], dim = \"time\")\n",
    "# climarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These plots are good for understanding the distribution of T during the day\n",
    "# Tl1 = 15\n",
    "# Tl2 = Tl1 + 1\n",
    "# l =(np.invert(np.isnan(\n",
    "#             np.where((T>=Tl1) & (T<=Tl2) ,T,np.nan)\n",
    "#         )))\n",
    "# print(np.sum(l)/nt)\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(t,T)\n",
    "# plt.axhline(y=Tl1)\n",
    "# plt.axhline(y=Tl2)\n",
    "# plt.ylim((10,30))\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(t,l)\n",
    "# plt.show()\n",
    "\n",
    "# Tmin = 15\n",
    "# Tmax = 25\n",
    "# Tlo = -5.0\n",
    "# Thi = 50.0\n",
    "# Tint = 1.0\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(t,T,)\n",
    "# plt.ylim((10,30))\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(calc_dist_point(Tmin,Tmax,Tlo,Thi,Tint),Tl1s)\n",
    "# plt.ylim((10,30))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
